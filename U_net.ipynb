{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "  def __init__(self, input_channel, output_channel):\n",
    "    super(DoubleConv, self).__init__()\n",
    "    self.input_channel = input_channel\n",
    "    self.output_channel = output_channel\n",
    "    self.db_conv = nn.Sequential(\n",
    "      nn.Conv2d(self.input_channel, self.output_channel, 3, 1, 0),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(self.output_channel, self.output_channel, 3, 1, 0),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.db_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                input_channel=3, \n",
    "                output_channel=2, \n",
    "                hidden_channels=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.down_sample = nn.Sequential()\n",
    "        self.middle = None\n",
    "        self.up_sample = nn.Sequential()\n",
    "        self.final_layer = None\n",
    "        self.max_pooling = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "        # Define down_sample\n",
    "        in_c = input_channel\n",
    "        for channel in hidden_channels:\n",
    "            self.down_sample.append(DoubleConv(in_c, channel))\n",
    "            in_c = channel\n",
    "        \n",
    "        # Define middle\n",
    "        self.middle = DoubleConv(hidden_channels[-1], hidden_channels[-1] * 2)\n",
    "    \n",
    "        # Define up_sample\n",
    "        in_c = hidden_channels[-1] * 2\n",
    "        for channel in reversed(hidden_channels):\n",
    "            self.up_sample.append(nn.ConvTranspose2d(in_c, in_c // 2, 2, 2))\n",
    "            self.up_sample.append(DoubleConv(in_c, channel))\n",
    "            in_c = channel\n",
    "    \n",
    "        # Define final layer\n",
    "        self.final_layer = nn.Conv2d(in_c, output_channel, 1, 1, 0)\n",
    "    \n",
    "    def crop_center_fm(self, feature_map, out_shape):\n",
    "        w, h = feature_map.shape[2], feature_map.shape[3]\n",
    "        diff_w, diff_h = (w - out_shape[2]) // 2, (h - out_shape[3]) // 2\n",
    "        return feature_map[:, :, diff_w:(w-diff_w), diff_h:(h - diff_h)]\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        print(\"Down sample shape\")\n",
    "        for down in self.down_sample:\n",
    "            x = down(x)\n",
    "            skip_connections = [x] + skip_connections\n",
    "            x = self.max_pooling(x)\n",
    "      \n",
    "        x = self.middle(x)\n",
    "        print(\"Mid sample shape: \", x.shape)\n",
    "    \n",
    "        print(\"Up sample shape\")\n",
    "        for i in range(0, len(self.up_sample), 2):\n",
    "            upper = self.up_sample[i]\n",
    "            conv = self.up_sample[i + 1]\n",
    "            x = upper(x)\n",
    "            cropped = self.crop_center_fm(skip_connections[i // 2], x.shape)\n",
    "            skip_connection = torch.concat((cropped, x), dim=1) \n",
    "            x = conv(skip_connection)\n",
    "            print(x.shape)\n",
    "        x = self.final_layer(x)\n",
    "\n",
    "        return x\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
